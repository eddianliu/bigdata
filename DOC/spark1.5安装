1.ubuntu系统开启root密码，能远程登陆root用户，
并且root用户能远程ssh ---免密码---  登陆
主节点，root用户能ssh localhost（就是主节点也要ssh-copy-i binend   主节点域名）

2.配置环境变了
sudo gedit /etc/profile
export PATH=$PATH:/home/titanic/soft/spark1.5/spark-1.5.0-bin-hadoop2.6/bin

3.要把hive的配置/opt/cloudera/parcels/CDH/lib/hive/conf/hive-site.xml,文件
这个文件拷贝到spark/conf/目录下面

4.配置spark  目录下面conf/spark-env.sh
----------------------------------------------------------------------------
#jdk环境变了
export JAVA_HOME=/usr/lib/jvm/java-7-oracle-cloudera

#hive的jar目录
export CLASSPATH=$CLASSPATH:/opt/cloudera/parcels/CDH/lib/hive/lib
#export SCALA_HOME=/opt/cloudera/parcels/CDH/lib/scala

#主节点的域名host
export SPARK_MASTER_IP=binend

#端口，默认
export SPARK_MASTER_PORT=7077

#spark使用内存1G
export SPARK_WORKER_MEMORY=1g

#spark使用on-yarn模式，要配置hadoop的onf目录，这里配置的是cloudera的hadoop的conf目录
export HADOOP_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hadoop/etc/hadoop
export YARN_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hadoop-yarn/etc/hadoop


#***********************************************
#这个是spark链接hadoop的yarn模式下的默认配置
#export SPARK_EXECUTOR_INSTANCES=6
#export SPARK_EXECUTOR_CORES=2
#export SPARK_EXECUTOR_MEMORY=6G
#export SPARK_DRIVER_MEMORY=2G
#在yarn中默认显示的名称
export SPARK_YARN_APP_NAME=tCloudSpark1.5.1
#***********************************************

#hive的配置目录使用spark，运行hive的sql
export HIVE_CONF_DIR=/opt/cloudera/parcels/CDH/lib/hive/conf
#export HIVE_SERVER2_THRIFT_PORT=10001
#export HIVE_SERVER2_THRIFT_BIND_HOST=binend

#照抄
export SPARK_CLASSPATH=$SPARK_CLASSPATH:/opt/cloudera/parcels/CDH/lib/hive/lib/mysql-connector-java-5.1.36.jar
export SPARK_JAR=/opt/cloudera/parcels/CDH/lib/spark-1.5.0/lib/spark-assembly-1.5.0-hadoop2.6.0.jar
-----------------------------------------------------------------------------------
4.配置spark目录下conf/slaves 文件  子节点host
binend
titanic
lan

5.启动集群。启动主节点sbin目录下面start-all.sh
6.关闭集群。关闭主节点sbin目录下面stop-all.sh  很慢，要等几分钟
--------------------------------------------------------------
spark启动./sbin/start-thriftserver.sh 模式,说明,就是启动一个jdbc服务.连接spark集群,spark集群使用yarn模式.
就相当于程序代码通过spark访问hive里面数据库的表.可以通过jdbc连接
./sbin/start-thriftserver.sh --master yarn --driver-memory 2G --executor-memory 6G  --hiveconf hive.server2.thrift.port=10001 --name spark-thriftserver

jdbc URL
jdbc:hive2://t1m1.tcloud.com:10001/data2
  2、经在公司的测试集群中进行相应的配置与调试得如下结论：
          （1）、Spark的运行模式的概念只是在提交作业(job)的时候，是把作业任务向yarn集群提交，还是向Spark的standalone的集群提交（前提是spark已经启动的standalone的集群的运行进程），在代码中需要指明master的标识来区别。
          （2）、在启动spark-thriftserver时，即可以把thriftserver的daemon的任务提交到yarn集群上运行，与可以向Spark的standalone的集群提交（前提是spark已经启动的standalone的集群的运行进程）
                    如果是向Spark的standalone的集群提交时需要用
${SPARK_HOME}/sbin/start-thriftserver.sh --driver-memory 2G --executor-memory 5G --master spark://t1m1.tcloud.com:7077 --hiveconf hive.server2.thrift.port=10001 --name spark-thriftserver
这个指令来启动thriftserver，对外提供服务；
                    如果是采用yarn模式运行thriftserver时，启动指令为：
${SPARK_HOME}/ sbin/start-thriftserver.sh --master yarn --driver-memory 2G --executor-memory 5G  --hiveconf hive.server2.thrift.port=10001 --name spark-thriftserver
          两者的区别在于master的参数值。
          
beeline：的使用跟模式无关   
${SPARK_HOME}/bin/beeline
beeline> !connect jdbc:hive2://t1m1.tcloud.com:10001
beeline >select city,count(*) from data2.lbs_app_weixin group by city;
其中，10001是spark thrift server的端口；data2表示hive数据库中数据库名；
